Context

Company X owns a movie application and repository that caters to movie streaming to millions of users on a subscription basis. The company wants to automate the process of cast and crew information in each scene from a movie such that when a user pauses on the movie and clicks on the cast information button, the app will show details of the actor in the scene. The company has in-house computer vision and multimedia experts who need to detect faces from screenshots of the movie scene.

Objective

Part A

To build a face detection system

Part B

To create an image dataset to be used by the AI team to build image classifier data

Part C

To build a face recognition system

Data Dictionary

Part A

label: Identifies the object in the image notes: Additional comments (currently empty) points: Coordinates of the mask (top-left and bottom-right) imageWidth: Width of the image in pixels imageHeight: Height of the image in pixels

Part B

The dataset comprises facial images that may contain either multiple individuals or a single individual per image.

Part C

This dataset consists of 10,770 images collected from Pinterest, featuring 100 individuals.

import os
import cv2
import keras
import pandas             as pd
import matplotlib.pyplot  as plt
import numpy              as np
import tensorflow         as tf
import pickle

from zipfile import ZipFile
%tensorflow_version 2.x
import tensorflow
tensorflow.__version__
Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.
'2.18.0'
from google.colab import drive
drive.mount('/content/drive')
Mounted at /content/drive
import os
print(os.listdir("../content"))
['.config', 'drive', 'sample_data']
import numpy as np
data = np.load('/content/drive/MyDrive/Images.npy', allow_pickle=True)
data[10][1]
[{'label': ['Face'],
  'notes': '',
  'points': [{'x': 0.046296296296296294, 'y': 0.16354166666666667},
   {'x': 0.2037037037037037, 'y': 0.2989583333333333}],
  'imageWidth': 648,
  'imageHeight': 960},
 {'label': ['Face'],
  'notes': '',
  'points': [{'x': 0.3194444444444444, 'y': 0.1375},
   {'x': 0.5570987654320988, 'y': 0.29583333333333334}],
  'imageWidth': 648,
  'imageHeight': 960},
 {'label': ['Face'],
  'notes': '',
  'points': [{'x': 0.5648148148148148, 'y': 0.1875},
   {'x': 0.7145061728395061, 'y': 0.30520833333333336}],
  'imageWidth': 648,
  'imageHeight': 960},
 {'label': ['Face'],
  'notes': '',
  'points': [{'x': 0.7160493827160493, 'y': 0.209375},
   {'x': 0.8333333333333334, 'y': 0.30625}],
  'imageWidth': 648,
  'imageHeight': 960},
 {'label': ['Face'],
  'notes': '',
  'points': [{'x': 0.8225308641975309, 'y': 0.23125},
   {'x': 0.9429012345679012, 'y': 0.3177083333333333}],
  'imageWidth': 648,
  'imageHeight': 960}]
Setting image dimensions

IMAGE_WIDTH = 224
IMAGE_HEIGHT = 224
import cv2
from tensorflow.keras.applications.mobilenet import preprocess_input

masks = np.zeros((int(data.shape[0]), IMAGE_HEIGHT, IMAGE_WIDTH))
X = np.zeros((int(data.shape[0]), IMAGE_HEIGHT, IMAGE_WIDTH, 3))
for index in range(data.shape[0]):
    img = data[index][0]
    img = cv2.resize(img, dsize=(IMAGE_HEIGHT, IMAGE_WIDTH), interpolation=cv2.INTER_CUBIC)
    try:
      img = img[:, :, :3]
    except:
      continue
    X[index] = preprocess_input(np.array(img, dtype=np.float32))
    for i in data[index][1]:
        x1 = int(i["points"][0]['x'] * IMAGE_WIDTH)
        x2 = int(i["points"][1]['x'] * IMAGE_WIDTH)
        y1 = int(i["points"][0]['y'] * IMAGE_HEIGHT)
        y2 = int(i["points"][1]['y'] * IMAGE_HEIGHT)
        masks[index][y1:y2, x1:x2] = 1
print("Total number of images in X:", X.shape[0])
print("Total number of masks in y:", masks.shape[0])
Total number of images in X: 393
Total number of masks in y: 393
#Splitting the data into training and testing
# 80% training, 20% testing split
split_ratio = 0.8
split_index = int(split_ratio * X.shape[0])  # 80% of 393

X_train = X[:split_index]
y_train = masks[:split_index]

X_test = X[split_index:]
y_test = masks[split_index:]

print("Training images:", X_train.shape[0])
print("Testing images:", X_test.shape[0])
Training images: 314
Testing images: 79
 
print("Total images:", X.shape[0])
print("Training images:", X_train.shape[0])
print("Testing images:", X_test.shape[0])
Total images: 393
Training images: 314
Testing images: 79
Printing a sample training image, image array and its mask

import matplotlib.pyplot as plt

n = 10
print("Image array:", X_train[n])
plt.imshow(X_train[n])
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.0..1.0].
Image array: [[[-0.95294118 -0.67058825 -0.56078434]
  [-0.95294118 -0.67058825 -0.56078434]
  [-0.95294118 -0.67058825 -0.56078434]
  ...
  [-0.92941177 -0.63137257 -0.52941179]
  [-0.92941177 -0.63137257 -0.52941179]
  [-0.92941177 -0.63137257 -0.52941179]]

 [[-0.95294118 -0.67058825 -0.56078434]
  [-0.95294118 -0.67058825 -0.56078434]
  [-0.95294118 -0.67058825 -0.56078434]
  ...
  [-0.92941177 -0.63137257 -0.52941179]
  [-0.92941177 -0.63137257 -0.52941179]
  [-0.92941177 -0.63137257 -0.52941179]]

 [[-0.95294118 -0.67058825 -0.56078434]
  [-0.95294118 -0.67058825 -0.56078434]
  [-0.95294118 -0.67058825 -0.56078434]
  ...
  [-0.92941177 -0.63137257 -0.52941179]
  [-0.92941177 -0.63137257 -0.52941179]
  [-0.92941177 -0.63137257 -0.52941179]]

 ...

 [[-0.99215686 -0.99215686 -0.99215686]
  [-0.99215686 -0.99215686 -0.99215686]
  [-0.99215686 -0.99215686 -0.99215686]
  ...
  [-0.99215686 -0.99215686 -0.99215686]
  [-0.99215686 -0.99215686 -0.99215686]
  [-0.99215686 -0.99215686 -0.99215686]]

 [[-0.95294118 -0.95294118 -0.95294118]
  [-1.         -1.         -1.        ]
  [-0.372549   -0.372549   -0.372549  ]
  ...
  [-0.36470586 -0.36470586 -0.36470586]
  [-1.         -1.         -1.        ]
  [-1.         -1.         -1.        ]]

 [[-0.99215686 -0.99215686 -0.99215686]
  [-0.97647059 -0.97647059 -0.97647059]
  [-0.94509804 -0.94509804 -0.94509804]
  ...
  [-0.95294118 -0.95294118 -0.95294118]
  [-1.         -1.         -1.        ]
  [-1.         -1.         -1.        ]]]
<matplotlib.image.AxesImage at 0x7e3d885cf310>
No description has been provided for this image
plt.imshow(masks[n])
<matplotlib.image.AxesImage at 0x7e3d7696e0d0>
No description has been provided for this image
Create the model

from tensorflow.keras.applications.mobilenet import MobileNet
from tensorflow.keras.layers import Reshape, UpSampling2D, Concatenate, Conv2D
from tensorflow.keras.models import Model

def create_model(trainable=True):
    model = MobileNet(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3), include_top=False, alpha=1.0, weights="imagenet")

    for layer in model.layers:
        layer.trainable = trainable

    block0 = model.get_layer("conv_pw_1_relu").output
    block1 = model.get_layer("conv_pw_3_relu").output
    block2 = model.get_layer("conv_pw_5_relu").output
    block3 = model.get_layer("conv_pw_11_relu").output
    block4 = model.get_layer("conv_pw_13_relu").output

    x = Concatenate()([UpSampling2D()(block4), block3])
    print(x.shape)
    x = Concatenate()([UpSampling2D()(x), block2])
    print(x.shape)
    x = Concatenate()([UpSampling2D()(x), block1])
    print(x.shape)
    x = Concatenate()([UpSampling2D()(x), block0])
    print(x.shape)
    x = UpSampling2D()(x)
    print(x.shape)
    x = Conv2D(1, kernel_size=1, activation="sigmoid")(x)
    x = Reshape((IMAGE_HEIGHT, IMAGE_WIDTH))(x)
    print(x.shape)

    return Model(inputs=model.input, outputs=x)
model = create_model()
Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5
17225924/17225924 ━━━━━━━━━━━━━━━━━━━━ 0s 0us/step
(None, 14, 14, 1536)
(None, 28, 28, 1792)
(None, 56, 56, 1920)
(None, 112, 112, 1984)
(None, 224, 224, 1984)
(None, 224, 224)
Printing model summary

model.summary()
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)              ┃ Output Shape           ┃        Param # ┃ Connected to           ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)  │ (None, 224, 224, 3)    │              0 │ -                      │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv1 (Conv2D)            │ (None, 112, 112, 32)   │            864 │ input_layer[0][0]      │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv1_bn                  │ (None, 112, 112, 32)   │            128 │ conv1[0][0]            │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv1_relu (ReLU)         │ (None, 112, 112, 32)   │              0 │ conv1_bn[0][0]         │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_1                 │ (None, 112, 112, 32)   │            288 │ conv1_relu[0][0]       │
│ (DepthwiseConv2D)         │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_1_bn              │ (None, 112, 112, 32)   │            128 │ conv_dw_1[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_1_relu (ReLU)     │ (None, 112, 112, 32)   │              0 │ conv_dw_1_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_1 (Conv2D)        │ (None, 112, 112, 64)   │          2,048 │ conv_dw_1_relu[0][0]   │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_1_bn              │ (None, 112, 112, 64)   │            256 │ conv_pw_1[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_1_relu (ReLU)     │ (None, 112, 112, 64)   │              0 │ conv_pw_1_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pad_2                │ (None, 113, 113, 64)   │              0 │ conv_pw_1_relu[0][0]   │
│ (ZeroPadding2D)           │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_2                 │ (None, 56, 56, 64)     │            576 │ conv_pad_2[0][0]       │
│ (DepthwiseConv2D)         │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_2_bn              │ (None, 56, 56, 64)     │            256 │ conv_dw_2[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_2_relu (ReLU)     │ (None, 56, 56, 64)     │              0 │ conv_dw_2_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_2 (Conv2D)        │ (None, 56, 56, 128)    │          8,192 │ conv_dw_2_relu[0][0]   │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_2_bn              │ (None, 56, 56, 128)    │            512 │ conv_pw_2[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_2_relu (ReLU)     │ (None, 56, 56, 128)    │              0 │ conv_pw_2_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_3                 │ (None, 56, 56, 128)    │          1,152 │ conv_pw_2_relu[0][0]   │
│ (DepthwiseConv2D)         │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_3_bn              │ (None, 56, 56, 128)    │            512 │ conv_dw_3[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_3_relu (ReLU)     │ (None, 56, 56, 128)    │              0 │ conv_dw_3_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_3 (Conv2D)        │ (None, 56, 56, 128)    │         16,384 │ conv_dw_3_relu[0][0]   │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_3_bn              │ (None, 56, 56, 128)    │            512 │ conv_pw_3[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_3_relu (ReLU)     │ (None, 56, 56, 128)    │              0 │ conv_pw_3_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pad_4                │ (None, 57, 57, 128)    │              0 │ conv_pw_3_relu[0][0]   │
│ (ZeroPadding2D)           │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_4                 │ (None, 28, 28, 128)    │          1,152 │ conv_pad_4[0][0]       │
│ (DepthwiseConv2D)         │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_4_bn              │ (None, 28, 28, 128)    │            512 │ conv_dw_4[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_4_relu (ReLU)     │ (None, 28, 28, 128)    │              0 │ conv_dw_4_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_4 (Conv2D)        │ (None, 28, 28, 256)    │         32,768 │ conv_dw_4_relu[0][0]   │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_4_bn              │ (None, 28, 28, 256)    │          1,024 │ conv_pw_4[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_4_relu (ReLU)     │ (None, 28, 28, 256)    │              0 │ conv_pw_4_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_5                 │ (None, 28, 28, 256)    │          2,304 │ conv_pw_4_relu[0][0]   │
│ (DepthwiseConv2D)         │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_5_bn              │ (None, 28, 28, 256)    │          1,024 │ conv_dw_5[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_5_relu (ReLU)     │ (None, 28, 28, 256)    │              0 │ conv_dw_5_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_5 (Conv2D)        │ (None, 28, 28, 256)    │         65,536 │ conv_dw_5_relu[0][0]   │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_5_bn              │ (None, 28, 28, 256)    │          1,024 │ conv_pw_5[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_5_relu (ReLU)     │ (None, 28, 28, 256)    │              0 │ conv_pw_5_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pad_6                │ (None, 29, 29, 256)    │              0 │ conv_pw_5_relu[0][0]   │
│ (ZeroPadding2D)           │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_6                 │ (None, 14, 14, 256)    │          2,304 │ conv_pad_6[0][0]       │
│ (DepthwiseConv2D)         │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_6_bn              │ (None, 14, 14, 256)    │          1,024 │ conv_dw_6[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_6_relu (ReLU)     │ (None, 14, 14, 256)    │              0 │ conv_dw_6_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_6 (Conv2D)        │ (None, 14, 14, 512)    │        131,072 │ conv_dw_6_relu[0][0]   │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_6_bn              │ (None, 14, 14, 512)    │          2,048 │ conv_pw_6[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_6_relu (ReLU)     │ (None, 14, 14, 512)    │              0 │ conv_pw_6_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_7                 │ (None, 14, 14, 512)    │          4,608 │ conv_pw_6_relu[0][0]   │
│ (DepthwiseConv2D)         │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_7_bn              │ (None, 14, 14, 512)    │          2,048 │ conv_dw_7[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_7_relu (ReLU)     │ (None, 14, 14, 512)    │              0 │ conv_dw_7_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_7 (Conv2D)        │ (None, 14, 14, 512)    │        262,144 │ conv_dw_7_relu[0][0]   │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_7_bn              │ (None, 14, 14, 512)    │          2,048 │ conv_pw_7[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_7_relu (ReLU)     │ (None, 14, 14, 512)    │              0 │ conv_pw_7_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_8                 │ (None, 14, 14, 512)    │          4,608 │ conv_pw_7_relu[0][0]   │
│ (DepthwiseConv2D)         │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_8_bn              │ (None, 14, 14, 512)    │          2,048 │ conv_dw_8[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_8_relu (ReLU)     │ (None, 14, 14, 512)    │              0 │ conv_dw_8_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_8 (Conv2D)        │ (None, 14, 14, 512)    │        262,144 │ conv_dw_8_relu[0][0]   │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_8_bn              │ (None, 14, 14, 512)    │          2,048 │ conv_pw_8[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_8_relu (ReLU)     │ (None, 14, 14, 512)    │              0 │ conv_pw_8_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_9                 │ (None, 14, 14, 512)    │          4,608 │ conv_pw_8_relu[0][0]   │
│ (DepthwiseConv2D)         │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_9_bn              │ (None, 14, 14, 512)    │          2,048 │ conv_dw_9[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_9_relu (ReLU)     │ (None, 14, 14, 512)    │              0 │ conv_dw_9_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_9 (Conv2D)        │ (None, 14, 14, 512)    │        262,144 │ conv_dw_9_relu[0][0]   │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_9_bn              │ (None, 14, 14, 512)    │          2,048 │ conv_pw_9[0][0]        │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_9_relu (ReLU)     │ (None, 14, 14, 512)    │              0 │ conv_pw_9_bn[0][0]     │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_10                │ (None, 14, 14, 512)    │          4,608 │ conv_pw_9_relu[0][0]   │
│ (DepthwiseConv2D)         │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_10_bn             │ (None, 14, 14, 512)    │          2,048 │ conv_dw_10[0][0]       │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_10_relu (ReLU)    │ (None, 14, 14, 512)    │              0 │ conv_dw_10_bn[0][0]    │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_10 (Conv2D)       │ (None, 14, 14, 512)    │        262,144 │ conv_dw_10_relu[0][0]  │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_10_bn             │ (None, 14, 14, 512)    │          2,048 │ conv_pw_10[0][0]       │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_10_relu (ReLU)    │ (None, 14, 14, 512)    │              0 │ conv_pw_10_bn[0][0]    │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_11                │ (None, 14, 14, 512)    │          4,608 │ conv_pw_10_relu[0][0]  │
│ (DepthwiseConv2D)         │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_11_bn             │ (None, 14, 14, 512)    │          2,048 │ conv_dw_11[0][0]       │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_11_relu (ReLU)    │ (None, 14, 14, 512)    │              0 │ conv_dw_11_bn[0][0]    │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_11 (Conv2D)       │ (None, 14, 14, 512)    │        262,144 │ conv_dw_11_relu[0][0]  │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_11_bn             │ (None, 14, 14, 512)    │          2,048 │ conv_pw_11[0][0]       │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_11_relu (ReLU)    │ (None, 14, 14, 512)    │              0 │ conv_pw_11_bn[0][0]    │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pad_12               │ (None, 15, 15, 512)    │              0 │ conv_pw_11_relu[0][0]  │
│ (ZeroPadding2D)           │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_12                │ (None, 7, 7, 512)      │          4,608 │ conv_pad_12[0][0]      │
│ (DepthwiseConv2D)         │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_12_bn             │ (None, 7, 7, 512)      │          2,048 │ conv_dw_12[0][0]       │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_12_relu (ReLU)    │ (None, 7, 7, 512)      │              0 │ conv_dw_12_bn[0][0]    │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_12 (Conv2D)       │ (None, 7, 7, 1024)     │        524,288 │ conv_dw_12_relu[0][0]  │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_12_bn             │ (None, 7, 7, 1024)     │          4,096 │ conv_pw_12[0][0]       │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_12_relu (ReLU)    │ (None, 7, 7, 1024)     │              0 │ conv_pw_12_bn[0][0]    │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_13                │ (None, 7, 7, 1024)     │          9,216 │ conv_pw_12_relu[0][0]  │
│ (DepthwiseConv2D)         │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_13_bn             │ (None, 7, 7, 1024)     │          4,096 │ conv_dw_13[0][0]       │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_dw_13_relu (ReLU)    │ (None, 7, 7, 1024)     │              0 │ conv_dw_13_bn[0][0]    │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_13 (Conv2D)       │ (None, 7, 7, 1024)     │      1,048,576 │ conv_dw_13_relu[0][0]  │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_13_bn             │ (None, 7, 7, 1024)     │          4,096 │ conv_pw_13[0][0]       │
│ (BatchNormalization)      │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv_pw_13_relu (ReLU)    │ (None, 7, 7, 1024)     │              0 │ conv_pw_13_bn[0][0]    │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ up_sampling2d             │ (None, 14, 14, 1024)   │              0 │ conv_pw_13_relu[0][0]  │
│ (UpSampling2D)            │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ concatenate (Concatenate) │ (None, 14, 14, 1536)   │              0 │ up_sampling2d[0][0],   │
│                           │                        │                │ conv_pw_11_relu[0][0]  │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ up_sampling2d_1           │ (None, 28, 28, 1536)   │              0 │ concatenate[0][0]      │
│ (UpSampling2D)            │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ concatenate_1             │ (None, 28, 28, 1792)   │              0 │ up_sampling2d_1[0][0], │
│ (Concatenate)             │                        │                │ conv_pw_5_relu[0][0]   │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ up_sampling2d_2           │ (None, 56, 56, 1792)   │              0 │ concatenate_1[0][0]    │
│ (UpSampling2D)            │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ concatenate_2             │ (None, 56, 56, 1920)   │              0 │ up_sampling2d_2[0][0], │
│ (Concatenate)             │                        │                │ conv_pw_3_relu[0][0]   │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ up_sampling2d_3           │ (None, 112, 112, 1920) │              0 │ concatenate_2[0][0]    │
│ (UpSampling2D)            │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ concatenate_3             │ (None, 112, 112, 1984) │              0 │ up_sampling2d_3[0][0], │
│ (Concatenate)             │                        │                │ conv_pw_1_relu[0][0]   │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ up_sampling2d_4           │ (None, 224, 224, 1984) │              0 │ concatenate_3[0][0]    │
│ (UpSampling2D)            │                        │                │                        │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ conv2d (Conv2D)           │ (None, 224, 224, 1)    │          1,985 │ up_sampling2d_4[0][0]  │
├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤
│ reshape (Reshape)         │ (None, 224, 224)       │              0 │ conv2d[0][0]           │
└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘
 Total params: 3,230,849 (12.32 MB)
 Trainable params: 3,208,961 (12.24 MB)
 Non-trainable params: 21,888 (85.50 KB)
from tensorflow import reduce_sum
from tensorflow.keras.backend import epsilon

def dice_coefficient(y_true, y_pred):
    numerator = 2 * reduce_sum(y_true * y_pred)
    denominator = reduce_sum(y_true + y_pred)
    return numerator / (denominator + epsilon())
from tensorflow.keras.losses import binary_crossentropy
from tensorflow.keras.backend import log

def loss(y_true, y_pred):
    return binary_crossentropy(y_true, y_pred) - log(dice_coefficient(y_true, y_pred) + epsilon())
model.compile(loss=loss, optimizer='adam', metrics=[dice_coefficient])
Using ModelCheckpoint

Using EarlyStopping

Using ReduceLROnPlateau

from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

checkpoint = ModelCheckpoint("model-{loss:.2f}.weights.h5", monitor="loss", verbose=1, save_best_only=True,
                             save_weights_only=True, mode="min")  # Change the filename to end with .weights.h5
stop = EarlyStopping(monitor="loss", patience=5, mode="min")
reduce_lr = ReduceLROnPlateau(monitor="loss", factor=0.2, patience=5, min_lr=1e-6, verbose=1, mode="min")
Fitting the model using below parameters epochs: 10 batch_size: 1 callbacks: using the callbacks defined above

# Fitting the model using below parameters epochs: 10 batch_size

history = model.fit(X_train, y_train, epochs=10, batch_size=1, callbacks=[checkpoint, stop, reduce_lr])
Epoch 1/10
312/314 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step - dice_coefficient: 0.4340 - loss: 1.5939
Epoch 1: loss improved from inf to 1.27932, saving model to model-1.28.weights.h5
314/314 ━━━━━━━━━━━━━━━━━━━━ 38s 22ms/step - dice_coefficient: 0.4347 - loss: 1.5909 - learning_rate: 0.0010
Epoch 2/10
312/314 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - dice_coefficient: 0.5672 - loss: 1.0096
Epoch 2: loss improved from 1.27932 to 0.86936, saving model to model-0.87.weights.h5
314/314 ━━━━━━━━━━━━━━━━━━━━ 7s 24ms/step - dice_coefficient: 0.5675 - loss: 1.0083 - learning_rate: 0.0010
Epoch 3/10
313/314 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - dice_coefficient: 0.6741 - loss: 0.6333
Epoch 3: loss improved from 0.86936 to 0.74575, saving model to model-0.75.weights.h5
314/314 ━━━━━━━━━━━━━━━━━━━━ 10s 24ms/step - dice_coefficient: 0.6739 - loss: 0.6340 - learning_rate: 0.0010
Epoch 4/10
313/314 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - dice_coefficient: 0.6984 - loss: 0.5596
Epoch 4: loss improved from 0.74575 to 0.62262, saving model to model-0.62.weights.h5
314/314 ━━━━━━━━━━━━━━━━━━━━ 7s 23ms/step - dice_coefficient: 0.6984 - loss: 0.5600 - learning_rate: 0.0010
Epoch 5/10
313/314 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - dice_coefficient: 0.7073 - loss: 0.5778
Epoch 5: loss improved from 0.62262 to 0.60762, saving model to model-0.61.weights.h5
314/314 ━━━━━━━━━━━━━━━━━━━━ 10s 23ms/step - dice_coefficient: 0.7072 - loss: 0.5780 - learning_rate: 0.0010
Epoch 6/10
313/314 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - dice_coefficient: 0.6825 - loss: 0.6750
Epoch 6: loss did not improve from 0.60762
314/314 ━━━━━━━━━━━━━━━━━━━━ 10s 22ms/step - dice_coefficient: 0.6825 - loss: 0.6747 - learning_rate: 0.0010
Epoch 7/10
314/314 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step - dice_coefficient: 0.7269 - loss: 0.5331
Epoch 7: loss improved from 0.60762 to 0.52625, saving model to model-0.53.weights.h5
314/314 ━━━━━━━━━━━━━━━━━━━━ 10s 23ms/step - dice_coefficient: 0.7270 - loss: 0.5331 - learning_rate: 0.0010
Epoch 8/10
314/314 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - dice_coefficient: 0.7714 - loss: 0.4603
Epoch 8: loss improved from 0.52625 to 0.43093, saving model to model-0.43.weights.h5
314/314 ━━━━━━━━━━━━━━━━━━━━ 10s 23ms/step - dice_coefficient: 0.7714 - loss: 0.4602 - learning_rate: 0.0010
Epoch 9/10
313/314 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - dice_coefficient: 0.8016 - loss: 0.3752
Epoch 9: loss improved from 0.43093 to 0.40391, saving model to model-0.40.weights.h5
314/314 ━━━━━━━━━━━━━━━━━━━━ 10s 23ms/step - dice_coefficient: 0.8015 - loss: 0.3754 - learning_rate: 0.0010
Epoch 10/10
312/314 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - dice_coefficient: 0.7927 - loss: 0.3872
Epoch 10: loss improved from 0.40391 to 0.39457, saving model to model-0.39.weights.h5
314/314 ━━━━━━━━━━━━━━━━━━━━ 11s 24ms/step - dice_coefficient: 0.7927 - loss: 0.3872 - learning_rate: 0.0010
m = 3
plt.imshow(X_test[m])
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.0..1.0].
<matplotlib.image.AxesImage at 0x7e3d485a3d50>
No description has been provided for this image
m = 3  # Ensure 0 <= m < len(X_test)

plt.figure(figsize=(6,6))
plt.subplot(1, 2, 1)
plt.imshow(X_test[m])  # Display test image
plt.title("Test Image")

plt.subplot(1, 2, 2)
plt.imshow(y_test[m], cmap="gray")  # Display mask (use grayscale for masks)
plt.title("Mask")

plt.show()
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.0..1.0].
No description has been provided for this image
Predicting the mask on the test image

m = 3  # Choose an index within range

# Predict mask
pred_mask = model.predict(np.expand_dims(X_test[m], axis=0))[0]

# Convert the predicted mask into binary (thresholding)
threshold = 0.5
pred_mask_binary = (pred_mask > threshold).astype(np.uint8)
1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))

# Original Image
plt.subplot(1, 3, 1)
plt.imshow(X_test[m])
plt.title("Original Image")

# True Mask
plt.subplot(1, 3, 2)
plt.imshow(y_test[m], cmap="gray")
plt.title("True Mask")

# Predicted Mask
plt.subplot(1, 3, 3)
plt.imshow(pred_mask_binary, cmap="gray")
plt.title("Predicted Mask")

plt.show()
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.0..1.0].
No description has been provided for this image
import cv2
kernel = np.ones((5,5), np.uint8)
pred_mask_binary = cv2.morphologyEx(pred_mask_binary, cv2.MORPH_OPEN, kernel)  # Removes small noise
pred_mask_binary = cv2.morphologyEx(pred_mask_binary, cv2.MORPH_CLOSE, kernel) # Fills small holes
threshold = 0.3  # Try lowering the threshold
pred_mask_binary = (pred_mask > threshold).astype(np.uint8)
from tensorflow.keras.optimizers import Adam

# model with a lower learning rate
model.compile(loss=loss,
              optimizer=Adam(learning_rate=1e-4),
              metrics=[dice_coefficient])
from sklearn.model_selection import train_test_split

# Splitting dataset
X_train, X_test, y_train, y_test = train_test_split(X, masks, test_size=0.2, random_state=42)

# Check if the split is correct
print(f"Training images: {len(X_train)}, Testing images: {len(X_test)}")
Training images: 314, Testing images: 79
model.fit(X_train, y_train,
          epochs=20,  # Increase epochs for better training
          batch_size=4,
          callbacks=[checkpoint, reduce_lr, stop],
          validation_data=(X_test, y_test))  # Validate on 79 images
Epoch 1/20
79/79 ━━━━━━━━━━━━━━━━━━━━ 0s 222ms/step - dice_coefficient: 0.7478 - loss: 0.4678
Epoch 1: loss did not improve from 0.39457
79/79 ━━━━━━━━━━━━━━━━━━━━ 52s 305ms/step - dice_coefficient: 0.7479 - loss: 0.4676 - val_dice_coefficient: 0.7446 - val_loss: 0.4886 - learning_rate: 1.0000e-04
Epoch 2/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - dice_coefficient: 0.7833 - loss: 0.3746
Epoch 2: loss improved from 0.39457 to 0.37837, saving model to model-0.38.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 11s 94ms/step - dice_coefficient: 0.7833 - loss: 0.3747 - val_dice_coefficient: 0.7704 - val_loss: 0.4270 - learning_rate: 1.0000e-04
Epoch 3/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - dice_coefficient: 0.8030 - loss: 0.3372
Epoch 3: loss improved from 0.37837 to 0.34186, saving model to model-0.34.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 10s 95ms/step - dice_coefficient: 0.8030 - loss: 0.3373 - val_dice_coefficient: 0.7802 - val_loss: 0.4048 - learning_rate: 1.0000e-04
Epoch 4/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - dice_coefficient: 0.8151 - loss: 0.3096
Epoch 4: loss improved from 0.34186 to 0.31931, saving model to model-0.32.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 10s 93ms/step - dice_coefficient: 0.8150 - loss: 0.3098 - val_dice_coefficient: 0.7842 - val_loss: 0.3941 - learning_rate: 1.0000e-04
Epoch 5/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - dice_coefficient: 0.8292 - loss: 0.2812
Epoch 5: loss improved from 0.31931 to 0.29357, saving model to model-0.29.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 10s 94ms/step - dice_coefficient: 0.8291 - loss: 0.2816 - val_dice_coefficient: 0.7875 - val_loss: 0.3917 - learning_rate: 1.0000e-04
Epoch 6/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - dice_coefficient: 0.8320 - loss: 0.2807
Epoch 6: loss improved from 0.29357 to 0.28551, saving model to model-0.29.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 8s 96ms/step - dice_coefficient: 0.8320 - loss: 0.2808 - val_dice_coefficient: 0.7898 - val_loss: 0.3832 - learning_rate: 1.0000e-04
Epoch 7/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - dice_coefficient: 0.8334 - loss: 0.2700
Epoch 7: loss improved from 0.28551 to 0.26959, saving model to model-0.27.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 10s 95ms/step - dice_coefficient: 0.8334 - loss: 0.2700 - val_dice_coefficient: 0.7905 - val_loss: 0.3833 - learning_rate: 1.0000e-04
Epoch 8/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - dice_coefficient: 0.8480 - loss: 0.2552
Epoch 8: loss improved from 0.26959 to 0.25554, saving model to model-0.26.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 10s 93ms/step - dice_coefficient: 0.8479 - loss: 0.2552 - val_dice_coefficient: 0.7914 - val_loss: 0.3836 - learning_rate: 1.0000e-04
Epoch 9/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - dice_coefficient: 0.8493 - loss: 0.2531
Epoch 9: loss improved from 0.25554 to 0.24800, saving model to model-0.25.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 10s 96ms/step - dice_coefficient: 0.8492 - loss: 0.2529 - val_dice_coefficient: 0.7920 - val_loss: 0.3867 - learning_rate: 1.0000e-04
Epoch 10/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - dice_coefficient: 0.8474 - loss: 0.2418
Epoch 10: loss improved from 0.24800 to 0.24151, saving model to model-0.24.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 8s 98ms/step - dice_coefficient: 0.8475 - loss: 0.2418 - val_dice_coefficient: 0.7943 - val_loss: 0.3798 - learning_rate: 1.0000e-04
Epoch 11/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - dice_coefficient: 0.8502 - loss: 0.2406
Epoch 11: loss improved from 0.24151 to 0.23816, saving model to model-0.24.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 8s 98ms/step - dice_coefficient: 0.8503 - loss: 0.2405 - val_dice_coefficient: 0.7958 - val_loss: 0.3800 - learning_rate: 1.0000e-04
Epoch 12/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - dice_coefficient: 0.8572 - loss: 0.2320
Epoch 12: loss improved from 0.23816 to 0.23536, saving model to model-0.24.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 8s 95ms/step - dice_coefficient: 0.8571 - loss: 0.2321 - val_dice_coefficient: 0.7956 - val_loss: 0.3802 - learning_rate: 1.0000e-04
Epoch 13/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - dice_coefficient: 0.8585 - loss: 0.2295
Epoch 13: loss improved from 0.23536 to 0.23127, saving model to model-0.23.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 8s 99ms/step - dice_coefficient: 0.8585 - loss: 0.2296 - val_dice_coefficient: 0.7956 - val_loss: 0.3797 - learning_rate: 1.0000e-04
Epoch 14/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - dice_coefficient: 0.8604 - loss: 0.2239
Epoch 14: loss improved from 0.23127 to 0.22566, saving model to model-0.23.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 8s 97ms/step - dice_coefficient: 0.8604 - loss: 0.2240 - val_dice_coefficient: 0.7981 - val_loss: 0.3767 - learning_rate: 1.0000e-04
Epoch 15/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - dice_coefficient: 0.8656 - loss: 0.2199
Epoch 15: loss improved from 0.22566 to 0.22203, saving model to model-0.22.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 8s 97ms/step - dice_coefficient: 0.8655 - loss: 0.2200 - val_dice_coefficient: 0.7982 - val_loss: 0.3756 - learning_rate: 1.0000e-04
Epoch 16/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - dice_coefficient: 0.8675 - loss: 0.2140
Epoch 16: loss improved from 0.22203 to 0.21921, saving model to model-0.22.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 10s 97ms/step - dice_coefficient: 0.8674 - loss: 0.2142 - val_dice_coefficient: 0.7931 - val_loss: 0.3880 - learning_rate: 1.0000e-04
Epoch 17/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - dice_coefficient: 0.8618 - loss: 0.2201
Epoch 17: loss improved from 0.21921 to 0.21825, saving model to model-0.22.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 10s 97ms/step - dice_coefficient: 0.8619 - loss: 0.2200 - val_dice_coefficient: 0.7945 - val_loss: 0.3836 - learning_rate: 1.0000e-04
Epoch 18/20
78/79 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - dice_coefficient: 0.8624 - loss: 0.2162
Epoch 18: loss improved from 0.21825 to 0.21379, saving model to model-0.21.weights.h5
79/79 ━━━━━━━━━━━━━━━━━━━━ 10s 94ms/step - dice_coefficient: 0.8625 - loss: 0.2162 - val_dice_coefficient: 0.8008 - val_loss: 0.3736 - learning_rate: 1.0000e-04
Epoch 19/20
 4/79 ━━━━━━━━━━━━━━━━━━━━ 6s 90ms/step - dice_coefficient: 0.8875 - loss: 0.1677
from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

train_generator = datagen.flow(X_train, y_train, batch_size=8)
from tensorflow.keras.optimizers import Adam

model.compile(optimizer=Adam(learning_rate=1e-5), loss=loss, metrics=[dice_coefficient])
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=8, callbacks=[checkpoint, stop, reduce_lr])
Epoch 1/20
40/40 ━━━━━━━━━━━━━━━━━━━━ 0s 357ms/step - dice_coefficient: 0.8752 - loss: 0.1942
Epoch 1: loss improved from 0.21060 to 0.20195, saving model to model-0.20.weights.h5
40/40 ━━━━━━━━━━━━━━━━━━━━ 50s 529ms/step - dice_coefficient: 0.8752 - loss: 0.1944 - val_dice_coefficient: 0.8041 - val_loss: 0.3687 - learning_rate: 1.0000e-05
Epoch 2/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 163ms/step - dice_coefficient: 0.8763 - loss: 0.1974
Epoch 2: loss improved from 0.20195 to 0.19923, saving model to model-0.20.weights.h5
40/40 ━━━━━━━━━━━━━━━━━━━━ 7s 184ms/step - dice_coefficient: 0.8762 - loss: 0.1974 - val_dice_coefficient: 0.8043 - val_loss: 0.3683 - learning_rate: 1.0000e-05
Epoch 3/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 164ms/step - dice_coefficient: 0.8783 - loss: 0.1987
Epoch 3: loss did not improve from 0.19923
40/40 ━━━━━━━━━━━━━━━━━━━━ 10s 172ms/step - dice_coefficient: 0.8781 - loss: 0.1987 - val_dice_coefficient: 0.8046 - val_loss: 0.3680 - learning_rate: 1.0000e-05
Epoch 4/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 165ms/step - dice_coefficient: 0.8774 - loss: 0.1988
Epoch 4: loss improved from 0.19923 to 0.19752, saving model to model-0.20.weights.h5
40/40 ━━━━━━━━━━━━━━━━━━━━ 11s 181ms/step - dice_coefficient: 0.8773 - loss: 0.1988 - val_dice_coefficient: 0.8043 - val_loss: 0.3688 - learning_rate: 1.0000e-05
Epoch 5/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 166ms/step - dice_coefficient: 0.8727 - loss: 0.2002
Epoch 5: loss improved from 0.19752 to 0.19585, saving model to model-0.20.weights.h5
40/40 ━━━━━━━━━━━━━━━━━━━━ 10s 182ms/step - dice_coefficient: 0.8729 - loss: 0.2000 - val_dice_coefficient: 0.8048 - val_loss: 0.3679 - learning_rate: 1.0000e-05
Epoch 6/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 165ms/step - dice_coefficient: 0.8742 - loss: 0.1965
Epoch 6: loss did not improve from 0.19585
40/40 ━━━━━━━━━━━━━━━━━━━━ 10s 173ms/step - dice_coefficient: 0.8743 - loss: 0.1966 - val_dice_coefficient: 0.8048 - val_loss: 0.3685 - learning_rate: 1.0000e-05
Epoch 7/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 163ms/step - dice_coefficient: 0.8752 - loss: 0.2002
Epoch 7: loss improved from 0.19585 to 0.19479, saving model to model-0.19.weights.h5
40/40 ━━━━━━━━━━━━━━━━━━━━ 7s 185ms/step - dice_coefficient: 0.8754 - loss: 0.1999 - val_dice_coefficient: 0.8050 - val_loss: 0.3682 - learning_rate: 1.0000e-05
Epoch 8/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 164ms/step - dice_coefficient: 0.8863 - loss: 0.1845
Epoch 8: loss did not improve from 0.19479
40/40 ━━━━━━━━━━━━━━━━━━━━ 10s 172ms/step - dice_coefficient: 0.8859 - loss: 0.1851 - val_dice_coefficient: 0.8051 - val_loss: 0.3687 - learning_rate: 1.0000e-05
Epoch 9/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 165ms/step - dice_coefficient: 0.8819 - loss: 0.1907
Epoch 9: loss did not improve from 0.19479
40/40 ━━━━━━━━━━━━━━━━━━━━ 11s 179ms/step - dice_coefficient: 0.8817 - loss: 0.1909 - val_dice_coefficient: 0.8048 - val_loss: 0.3690 - learning_rate: 1.0000e-05
Epoch 10/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 165ms/step - dice_coefficient: 0.8785 - loss: 0.1986
Epoch 10: loss did not improve from 0.19479
40/40 ━━━━━━━━━━━━━━━━━━━━ 7s 173ms/step - dice_coefficient: 0.8784 - loss: 0.1986 - val_dice_coefficient: 0.8048 - val_loss: 0.3689 - learning_rate: 1.0000e-05
Epoch 11/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 164ms/step - dice_coefficient: 0.8844 - loss: 0.1880
Epoch 11: loss did not improve from 0.19479
40/40 ━━━━━━━━━━━━━━━━━━━━ 10s 173ms/step - dice_coefficient: 0.8841 - loss: 0.1884 - val_dice_coefficient: 0.8049 - val_loss: 0.3693 - learning_rate: 1.0000e-05
Epoch 12/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 167ms/step - dice_coefficient: 0.8781 - loss: 0.1942
Epoch 12: loss improved from 0.19479 to 0.19397, saving model to model-0.19.weights.h5
40/40 ━━━━━━━━━━━━━━━━━━━━ 7s 183ms/step - dice_coefficient: 0.8781 - loss: 0.1942 - val_dice_coefficient: 0.8051 - val_loss: 0.3692 - learning_rate: 1.0000e-05
Epoch 13/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 166ms/step - dice_coefficient: 0.8751 - loss: 0.2023
Epoch 13: loss did not improve from 0.19397
40/40 ━━━━━━━━━━━━━━━━━━━━ 7s 180ms/step - dice_coefficient: 0.8753 - loss: 0.2020 - val_dice_coefficient: 0.8056 - val_loss: 0.3687 - learning_rate: 1.0000e-05
Epoch 14/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 164ms/step - dice_coefficient: 0.8759 - loss: 0.2010
Epoch 14: loss improved from 0.19397 to 0.19369, saving model to model-0.19.weights.h5
40/40 ━━━━━━━━━━━━━━━━━━━━ 10s 181ms/step - dice_coefficient: 0.8761 - loss: 0.2006 - val_dice_coefficient: 0.8054 - val_loss: 0.3689 - learning_rate: 1.0000e-05
Epoch 15/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 164ms/step - dice_coefficient: 0.8783 - loss: 0.1981
Epoch 15: loss did not improve from 0.19369
40/40 ━━━━━━━━━━━━━━━━━━━━ 10s 172ms/step - dice_coefficient: 0.8783 - loss: 0.1978 - val_dice_coefficient: 0.8059 - val_loss: 0.3683 - learning_rate: 1.0000e-05
Epoch 16/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 165ms/step - dice_coefficient: 0.8776 - loss: 0.1950
Epoch 16: loss improved from 0.19369 to 0.19314, saving model to model-0.19.weights.h5
40/40 ━━━━━━━━━━━━━━━━━━━━ 11s 181ms/step - dice_coefficient: 0.8777 - loss: 0.1949 - val_dice_coefficient: 0.8066 - val_loss: 0.3672 - learning_rate: 1.0000e-05
Epoch 17/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 167ms/step - dice_coefficient: 0.8804 - loss: 0.1952
Epoch 17: loss improved from 0.19314 to 0.19174, saving model to model-0.19.weights.h5
40/40 ━━━━━━━━━━━━━━━━━━━━ 10s 183ms/step - dice_coefficient: 0.8804 - loss: 0.1950 - val_dice_coefficient: 0.8063 - val_loss: 0.3675 - learning_rate: 1.0000e-05
Epoch 18/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 164ms/step - dice_coefficient: 0.8820 - loss: 0.1905
Epoch 18: loss improved from 0.19174 to 0.19167, saving model to model-0.19.weights.h5
40/40 ━━━━━━━━━━━━━━━━━━━━ 10s 181ms/step - dice_coefficient: 0.8818 - loss: 0.1905 - val_dice_coefficient: 0.8062 - val_loss: 0.3680 - learning_rate: 1.0000e-05
Epoch 19/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 164ms/step - dice_coefficient: 0.8792 - loss: 0.1931
Epoch 19: loss did not improve from 0.19167
40/40 ━━━━━━━━━━━━━━━━━━━━ 7s 172ms/step - dice_coefficient: 0.8792 - loss: 0.1932 - val_dice_coefficient: 0.8063 - val_loss: 0.3681 - learning_rate: 1.0000e-05
Epoch 20/20
39/40 ━━━━━━━━━━━━━━━━━━━━ 0s 166ms/step - dice_coefficient: 0.8766 - loss: 0.1910
Epoch 20: loss did not improve from 0.19167
40/40 ━━━━━━━━━━━━━━━━━━━━ 7s 179ms/step - dice_coefficient: 0.8767 - loss: 0.1911 - val_dice_coefficient: 0.8060 - val_loss: 0.3688 - learning_rate: 1.0000e-05
<keras.src.callbacks.history.History at 0x7e3cc4946090>
Dice Coefficient (Train): 0.8943 → Good! The model is learning.

Loss (Train): 0.1674 → Improving.

Dice Coefficient (Validation): 0.8517 → Slight improvement.

Loss (Validation): 0.2717 → Still higher than training loss → Overfitting is present.

Learning Rate Reduction: 1e-6 → The model is not improving much anymore. This means it's approaching its optimal state.

# Evaluate the model on the test set
test_loss, test_dice = model.evaluate(X_test, y_test, verbose=1)

print(f"Test Loss: {test_loss:.4f}")
print(f"Test Dice Coefficient: {test_dice:.4f}")
3/3 ━━━━━━━━━━━━━━━━━━━━ 9s 2s/step - dice_coefficient: 0.8057 - loss: 0.3639
Test Loss: 0.3660
Test Dice Coefficient: 0.8058
Dice Coefficient (0.8553): This is a good score, indicating that the model is performing well in segmenting the images. A perfect score would be 1.0.

Loss (0.2652): A lower loss is better.

import matplotlib.pyplot as plt

# Select a test image index
m = 5  # Change this index to view different images

# Get the test image and ground truth mask
test_img = X_test[m]
true_mask = y_test[m]

# Predict the mask
predicted_mask = model.predict(test_img.reshape(1, 224, 224, 3))[0]

# Plot the original image, true mask, and predicted mask
plt.figure(figsize=(12, 4))

# Original Image
plt.subplot(1, 3, 1)
plt.imshow(test_img)
plt.title("Original Image")
plt.axis("off")

# Ground Truth Mask
plt.subplot(1, 3, 2)
plt.imshow(true_mask, cmap="gray")
plt.title("True Mask")
plt.axis("off")

# Predicted Mask
plt.subplot(1, 3, 3)
plt.imshow(predicted_mask, cmap="gray")
plt.title("Predicted Mask")
plt.axis("off")

plt.show()
1/1 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.0..1.0].
No description has been provided for this image
 
import os

# Path to your Google Drive folder
image_folder = "/content/drive/MyDrive/training_images-20211126T092819Z-001 (1)/training_images"

# Verify the folder exists
if os.path.exists(image_folder):
    print("Folder found!")
else:
    print("Folder NOT found! Check the path.")
Folder found!
from tqdm import tqdm
!pip install opencv-python
import cv2
import os
from tqdm import tqdm
import pandas as pd
Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)
Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)
#Load OpenCV pre-trained face detection model
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

# List all images
image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
print(f"Total images found: {len(image_files)}")

# Data storage
face_data = []

# Loop through each image
for image_name in tqdm(image_files, desc="Processing Images"):
    img_path = os.path.join(image_folder, image_name)
    img = cv2.imread(img_path)

    if img is None:
        print(f"❌ Skipping {image_name} (Failed to load)")
        continue

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

    # Store data for each face
    for (x, y, w, h) in faces:
        face_data.append([image_name, x, y, w, h, len(faces)])

# Convert to DataFrame
df_faces = pd.DataFrame(face_data, columns=['Image', 'X', 'Y', 'Width', 'Height', 'Total_Faces'])

# Save as CSV
csv_path = "/content/drive/MyDrive/faces_metadata.csv"
df_faces.to_csv(csv_path, index=False)

print(f"✅ Face detection complete! Metadata saved at: {csv_path}")
df_faces.head()
Total images found: 1091
Processing Images:  87%|████████▋ | 945/1091 [02:47<00:25,  5.83it/s]
